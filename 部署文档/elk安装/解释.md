因为es.yaml内定义了nodeselector，所有要给需要部署的节点打赏对应标签es=data (另外注意如果filebeat的pod在某个节点部署不上可能是对应的节点有污点）  
`kubectl label node <node name> es=data`   
可用创建一个文件夹把文件全放进去
mkdir elk

先部署文件中的namespace.yaml创建一个命名空间
 
`kubectl apply -f namespace.yaml`  

然后部署文件中的其它yaml资源(或者先Elasticsearch再Logstash再filebeat最后Kibana）  

` kubectl apply -f elk/` 

根据kibana部署的节点以及像外部映射的端口来进行访问Web管理页面  
![image](https://github.com/user-attachments/assets/9c860416-e46a-4347-a56d-68f518142dab)  
![image](https://github.com/user-attachments/assets/90cf0d45-7274-42b7-9a78-bd0d0237ac71)  

浏览器访问 192.168.219.149:31326（node2节点的ip为192.168.219.149）  

---------
Elasticsearch：是一个分布式的搜索和分析引擎。它能够处理大量的数据，并提供快速、准确的搜索结果，支持复杂的数据分析和可视化。   

Logstash：是一个日志收集和处理工具。它可以从各种数据源收集数据，并对数据进行过滤、解析和转换，使其能够被Elasticsearch等系统所理解。  

Kibana：是一个数据可视化工具，提供了强大的图形化界面，能够帮助用户更好地理解和分析数据。它支持各种图表和图形，可以直观地展示数据趋势、关系和特征。  

filebeat是一个轻量级的数据收集工具进行收集  

filebeat通过Daemonset部署在每一个需要收集日志的节点上，Logstash，Kibana，Elasticsearch安装在主节点上  

filebeat从节点收集日志数据→Logstash接收并将数据进行清洗→Elasticsearch接收并将数据搜集、分析、存储→kibana从es中获取数据并提供可视化服务（仪表盘等）  

---
Filebeat 从以下路径采集日志数据：

/var/log/containers/*.log
这是 Kubernetes 中容器的标准日志路径。Kubernetes 会将每个容器的日志文件以 <pod-name>_<namespace>_<container-name>-<container-id>.log 的格式存储在 /var/log/containers/ 目录下。

/var/lib 和 /var/log
这些路径通过 hostPath 挂载到 Filebeat 容器中，确保 Filebeat 可以访问宿主机上的日志文件：

/var/lib：通常包含 Docker 或 Containerd 的容器运行时数据。

/var/log：包含 Kubernetes 的 Pod 日志（通过 /var/log/pods 和 /var/log/containers 的软链接）。

----------
也可以加入kafka处理消息 提升处理能力  
![image](https://github.com/user-attachments/assets/dbf883b9-3fed-40b1-be2d-df2f348fd4d1)


